{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load str file from /home/zj/PharmAI/pharm_ai/kwranking/ti2.json\n",
      "Load str file from /home/zj/PharmAI/pharm_ai/kwranking/indications.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "import datetime\n",
    "from wsgiref.headers import tspecials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import sys\n",
    "sys.path.append('PharmAI-master')\n",
    "from config import ConfigFilePaths\n",
    "from typing import List, Union, Optional\n",
    "import rule_match\n",
    "\n",
    "#需要查找关键词的文章路径\n",
    "path1 = '/home/zj/PharmAI/pharm_ai/kwranking/ti2.json'\n",
    "with open(path1, 'r+',encoding='utf-8') as f:\n",
    "    print(\"Load str file from {}\".format(path1))\n",
    "    str1 = f.read()\n",
    "    orig_ar = json.loads(str1)\n",
    "#print(type(orig_ar))\n",
    "path2 = '/home/zj/PharmAI/pharm_ai/kwranking/indications.json'\n",
    "with open(path2, 'r+',encoding='utf-8') as f:\n",
    "    print(\"Load str file from {}\".format(path2))\n",
    "    str2 = f.read()\n",
    "    indications = json.loads(str2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到中位数\n",
    "def get_median(data):\n",
    "    data = sorted(data)\n",
    "    size = len(data)\n",
    "    #if size == 0:\n",
    "        #data.append(0)\n",
    "    if size % 2 == 0: # 判断列表长度为偶数\n",
    "        median = (data[size//2]+data[size//2-1])/2\n",
    "        data[0] = median\n",
    "    if size % 2 == 1: # 判断列表长度为奇数\n",
    "        median = data[(size-1)//2]\n",
    "        data[0] = median\n",
    "    return data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查找适应症tags，得到位置和频率\n",
    "def find_inds(ids,article):\n",
    "    article = article.lower()\n",
    "    article = article.replace('-',' ')\n",
    "    char_s = re.split(\"。\",article)\n",
    "    n_sen = (len(char_s))-1\n",
    "    if n_sen==0:\n",
    "        n_sen=1\n",
    "    print('句子总数',n_sen)\n",
    "    sen=[]\n",
    "    count = []\n",
    "    ppp = []\n",
    "    for each in ids:\n",
    "        s=0\n",
    "        c=0\n",
    "        m=0\n",
    "        for item in indications:\n",
    "            if each == item.get('_id'):\n",
    "                if 'name_synonyms' not in item or item.get('name_synonyms')==\"\":\n",
    "                    each_name=[item.get('name'),item.get('name_en')]\n",
    "                else:\n",
    "                    each_name=[item.get('name'),item.get('name_en')]+item.get('name_synonyms')\n",
    "                #else:\n",
    "                    #each_name=[item.get('name'),item.get('name_en'),item.get('name_synonyms')]\n",
    "        print(each_name)\n",
    "        #each_name是当前id对应的所有名字的列表\n",
    "        mm=[]\n",
    "        for ea in each_name:\n",
    "            ea=ea.lower()\n",
    "            ea=ea.replace('-',' ')\n",
    "            print(ea)     \n",
    "            for con in char_s:\n",
    "                if ea in con:\n",
    "                    s+=1\n",
    "            pp=[]\n",
    "            for match in re.finditer(ea,article):\n",
    "                p = match.start()\n",
    "                e = match.end()\n",
    "                c += 1\n",
    "                print('Found {!r} at {:d}:{:d}'.format(article[p:e], p,e))  \n",
    "                pp.append(p)\n",
    "            if pp:\n",
    "                m1=get_median(pp)\n",
    "                mm.append(m1)\n",
    "        if mm:\n",
    "            m=get_median(mm)\n",
    "        else:\n",
    "            m=len(article)\n",
    "        sen.append(s/n_sen)\n",
    "        count.append(c)\n",
    "        ppp.append(m)\n",
    "    '''\n",
    "    if ss:\n",
    "        m = get_median(ss)\n",
    "    else:\n",
    "        m = len(article)\n",
    "    '''\n",
    "        #取位置的中位数\n",
    "        #如果没有出现，取为文章的长度\n",
    "\n",
    "    print('适应症关键词出现次数：',count)\n",
    "    print('出现的位置：',ppp)\n",
    "    print('句子占比',sen)\n",
    "    '''\n",
    "    order = []\n",
    "    sequence = pd.Series(sss)\n",
    "    order = len(sequence) - sequence.rank()\n",
    "    print(order)\n",
    "    '''\n",
    "    return count,ppp,sen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_id(name):\n",
    "    id=[]\n",
    "    for n in name:\n",
    "        for ind in indications:\n",
    "            if 'name_synonyms' not in ind or not ind.get('name_synonyms'):\n",
    "                if n==ind.get('name') and len(n)==len(ind.get('name')):\n",
    "                    id.append(ind.get('_id'))\n",
    "                    #print(ind.get('id'))\n",
    "                else:\n",
    "                    if n==ind.get('name_en') and len(n)==len(ind.get('name_en')):\n",
    "                        id.append(ind.get('_id'))\n",
    "            else:\n",
    "                if n==ind.get('name') and len(n)==len(ind.get('name')):\n",
    "                    id.append(ind.get('_id'))\n",
    "                    #print(ind.get('id'))\n",
    "                else:\n",
    "                    if n==ind.get('name_en') and len(n)==len(ind.get('name_en')):\n",
    "                        id.append(ind.get('_id'))\n",
    "                    else:\n",
    "                        for item in ind.get('name_synonyms'):\n",
    "                            if n==item and len(n)==len(item):\n",
    "                                id.append(ind.get('_id'))\n",
    "    return id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<<< HEAD:pharm_ai/pom/kwranking/test.ipynb
      "Load str file from /home/zj/PharmAI/pharm_ai/pom/kwranking/indications.json\n",
      "{1956}\n"
========
      "Load str file from /home/zj/PharmAI/pharm_ai/kwranking/indications.json\n",
      "(51, (1956, '肺炎'))\n",
      "51\n",
      "肺炎\n"
>>>>>>>> 0d68740f1618d19a460077008087e097a2bafb38:pharm_ai/kwranking/test.ipynb
     ]
    }
   ],
   "source": [
    "import ahocorasick\n",
    "import json\n",
    "\n",
<<<<<<<< HEAD:pharm_ai/pom/kwranking/test.ipynb
    "path2 = '/home/zj/PharmAI/pharm_ai/pom/kwranking/indications.json'\n",
========
    "path2 = '/home/zj/PharmAI/pharm_ai/kwranking/indications.json'\n",
>>>>>>>> 0d68740f1618d19a460077008087e097a2bafb38:pharm_ai/kwranking/test.ipynb
    "with open(path2, 'r+',encoding='utf-8') as f:\n",
    "    print(\"Load str file from {}\".format(path2))\n",
    "    str2 = f.read()\n",
    "    indications = json.loads(str2)\n",
    "\n",
    "\n",
    "A = ahocorasick.Automaton()\n",
    "inds=[]\n",
    "for item in indications:\n",
    "    if 'name_synonyms' not in item or item.get('name_synonyms'):\n",
    "        inds.append(item.get('name'))\n",
    "        inds.append(item.get('name_en'))\n",
    "    else:\n",
    "        inds.append(item.get('name'))\n",
    "        inds.append(item.get('name_en'))\n",
    "        inds+=item.get('name_synonyms')\n",
    "# 向trie树中添加单词\n",
    "for index,word in enumerate(inds):\n",
    "    A.add_word(word, (index, word))\n",
    "# 用法分析add_word(word,[value]) => bool\n",
    "# 根据Automaton构造函数的参数store设置，value这样考虑：\n",
    "# 1. 如果store设置为STORE_LENGTH，不能传递value，默认保存len(word)\n",
    "# 2. 如果store设置为STORE_INTS，value可选，但必须是int类型，默认是len(automaton)\n",
    "# 3. 如果store设置为STORE_ANY，value必须写，可以是任意类型\n",
    "'''\n",
    "# 测试单词是否在树中\n",
    "if \"he\" in A:\n",
    "    print True\n",
    "else:\n",
    "    print False\n",
    "A.get(\"he\")\n",
    "# (0,'he')\n",
    "A.get(\"cat\",\"<not exists>\")\n",
    "# '<not exists>'\n",
    "A.get(\"dog\")\n",
    "# KeyError\n",
    "那适应症和文章匹配的时候，记得全部换小写，去符号，去空格！！！\n",
    "判断是否有词语重合，用下面找出的结束位置减去词语长度可得到开始位置\n",
    "如果开始结束位置在另一个词里面，则删掉\n",
    "'''\n",
    "# 将trie树转化为Aho-Corasick自动机\n",
    "A.make_automaton()\n",
    "\n",
    "# 找到所有匹配字符串\n",
    "aa=[]\n",
<<<<<<<< HEAD:pharm_ai/pom/kwranking/test.ipynb
    "for item in A.iter(\"肺炎肺炎肺炎肺炎\"):\n",
    "    #print(item)\n",
    "    aa.append(item[1][0])\n",
    "    #print(item[0])\n",
    "    #print(item[1][1])\n",
    "aa=set(aa)\n",
    "print(aa)\n",
========
    "for item in A.iter(\"根据Worldometer实时统计数据，截至北京时间2022年2月25日6时30分，全球累计确诊新冠肺炎病例431546959例，累计死亡病例5944491例。 数据显示，德国、韩国、俄罗斯、美国、巴西是新增确诊病例数最多的五个国家。 美国、巴西、俄罗斯、墨西哥、波兰是新增死亡病例数最多的五个国家\"):\n",
    "    print(item)\n",
    "    aa.append(item)\n",
    "    print(item[0])\n",
    "    print(item[1][1])\n",
>>>>>>>> 0d68740f1618d19a460077008087e097a2bafb38:pharm_ai/kwranking/test.ipynb
    "#(2,(0,'he'))\n",
    "#(3,(1,'her'))\n",
    "#(4, (2, 'hers'))\n",
    "#(6, (3, 'she'))\n",
    "#(6, (0, 'he'))\n",
    "#print(type(aa))\n",
    "#print(aa[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "indoo='feixao'\n",
    "\n",
    "matched=[]\n",
    "\n",
    "matched.append(indoo[0])\n",
    "matched.remove(indoo[0])\n",
    "print(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "artic=[]\n",
    "for ar in orig_ar:\n",
    "    #modify_time=ar.get('modify_time')\n",
    "    #create_time=ar.get('create_time')\n",
    "    if 'tags' not in ar:\n",
    "        pass\n",
    "    else:\n",
    "        words = ar.get('content')\n",
    "        words = re.sub(\"\\n\",\" \",words)\n",
    "        content = str(re.findall(r'(>.*?\\<)',words))\n",
    "        content = content.replace('<','')\n",
    "        content = content.replace('>','')\n",
    "        content = content.replace(',','')\n",
    "        content = content.replace(\"'\",'')\n",
    "        content = content.replace('!','。')\n",
    "        content = content.replace('?','。')\n",
    "        #print(content)\n",
    "        if ar.get('abstract') == None:\n",
    "            text=\"\\n\" + ar.get('title') + \"。\"\n",
    "        else:\n",
    "            text=\"\\n\" + ar.get('title') + \"。\" + ar.get('abstract')+ \"。\"\n",
    "        #print(text)\n",
    "        tags = ar.get('tags')    \n",
    "        #print(tags)\n",
    "        #ids = ar.get('indication_ids')\n",
    "\n",
    "\n",
    "        matcher = rule_match.IndicationMatcher()\n",
    "        inds_c=matcher.match(content)\n",
    "        ids_c=find_id(inds_c)\n",
    "        #正文中的适应症,在查找的时候没管大小写，输出的是在词典name,mane_en,synonyms中出现的名字\n",
    "\n",
    "        inds_t=matcher.match(text)\n",
    "        ids_t=find_id(inds_t)\n",
    "        #标题摘要中的适应症\n",
    "\n",
    "        char=content+text\n",
    "        inds_a=matcher.match(char)\n",
    "        ids_a=find_id(inds_a)\n",
    "        #所有找到的适应症\n",
    "\n",
    "        tagstr=','.join(tags)\n",
    "        inds_tags=matcher.match(tagstr)\n",
    "        ids_tags=find_id(inds_tags)\n",
    "        if set(ids_tags)<set(ids_t):\n",
    "            artic.append(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 网址为： 4\n",
      "1 2\n"
<<<<<<<< HEAD:pharm_ai/pom/kwranking/test.ipynb
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nclanguage.name=\"Python教程\"\\nclanguage.add=\"http://c.biancheng.net/python\"\\n#调用clanguage的say()方法\\nclanguage.say(\"人生苦短，我用Python\")\\n#再次输出name和add的值\\nprint(clanguage.name,clanguage.add)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CLanguage :\n",
    "    # 下面定义了2个类变量\n",
    "    name = \"C语言中文网\"\n",
    "    add = \"http://c.biancheng.net\"\n",
    "    def __init__(self,name,add):\n",
    "        #下面定义 2 个实例变量\n",
    "        self.name = 1\n",
    "        self.add = 2\n",
    "        print(name,\"网址为：\",add)\n",
    "    # 下面定义了一个say实例方法\n",
    "    def say(self, content):\n",
    "        print(content)\n",
    "# 将该CLanguage对象赋给clanguage变量\n",
    "clanguage = CLanguage(\"3\",\"4\")\n",
    "#输出name和add实例变量的值\n",
    "print(clanguage.name,clanguage.add)\n",
    "#修改实例变量的值\n",
    "'''\n",
    "clanguage.name=\"Python教程\"\n",
    "clanguage.add=\"http://c.biancheng.net/python\"\n",
    "#调用clanguage的say()方法\n",
    "clanguage.say(\"人生苦短，我用Python\")\n",
    "#再次输出name和add的值\n",
    "print(clanguage.name,clanguage.add)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kkk\n"
========
>>>>>>>> 0d68740f1618d19a460077008087e097a2bafb38:pharm_ai/kwranking/test.ipynb
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nclanguage.name=\"Python教程\"\\nclanguage.add=\"http://c.biancheng.net/python\"\\n#调用clanguage的say()方法\\nclanguage.say(\"人生苦短，我用Python\")\\n#再次输出name和add的值\\nprint(clanguage.name,clanguage.add)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<<< HEAD:pharm_ai/pom/kwranking/test.ipynb
    "\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import ahocorasick\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "from wsgiref.headers import tspecials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('PharmAI-master')\n",
    "from config import ConfigFilePaths\n",
    "from typing import List, Union, Optional\n",
    "import unicodedata\n",
    "\n",
    "class keywords():\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self,inds_cdd: Optional[List[str]],ids_cdd: Optional[List[str]]):\n",
    "        self.inds_cdd=inds_cdd\n",
    "        self.ids_cdd=ids_cdd\n",
    "        #print(inds_cdd)\n",
    "    def prt(self,text):\n",
    "        print(text)\n",
    "    def ppp(self,text1):\n",
    "        keywords.prt(self,text1)\n",
    "\n",
    "a=keywords('keshi','dansh')\n",
    "a.ppp('kkk')"
========
    "class CLanguage :\n",
    "    # 下面定义了2个类变量\n",
    "    name = \"C语言中文网\"\n",
    "    add = \"http://c.biancheng.net\"\n",
    "    def __init__(self,name,add):\n",
    "        #下面定义 2 个实例变量\n",
    "        self.name = 1\n",
    "        self.add = 2\n",
    "        print(name,\"网址为：\",add)\n",
    "    # 下面定义了一个say实例方法\n",
    "    def say(self, content):\n",
    "        print(content)\n",
    "# 将该CLanguage对象赋给clanguage变量\n",
    "clanguage = CLanguage(\"3\",\"4\")\n",
    "#输出name和add实例变量的值\n",
    "print(clanguage.name,clanguage.add)\n",
    "#修改实例变量的值\n",
    "'''\n",
    "clanguage.name=\"Python教程\"\n",
    "clanguage.add=\"http://c.biancheng.net/python\"\n",
    "#调用clanguage的say()方法\n",
    "clanguage.say(\"人生苦短，我用Python\")\n",
    "#再次输出name和add的值\n",
    "print(clanguage.name,clanguage.add)\n",
    "'''"
>>>>>>>> 0d68740f1618d19a460077008087e097a2bafb38:pharm_ai/kwranking/test.ipynb
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
